{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "da07191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from models.tcn import TCN\n",
    "from exp.exp_informer import Exp_Informer\n",
    "from models.dtcn_encoder import *\n",
    "from models.tcn_encoder import *\n",
    "from models.lstm_encoder import LSTM_Encoder\n",
    "from models.informer_encoder import Informer_Encoder\n",
    "from pyats.datastructures import AttrDict\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "08ea469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "500adf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "aefaa954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_data(self, flag):\n",
    "    args = self.args\n",
    "\n",
    "    data_dict = {\n",
    "        'ETTh1':Dataset_ETT_hour,\n",
    "        'ETTh2':Dataset_ETT_hour,\n",
    "        'ETTm1':Dataset_ETT_minute,\n",
    "        'ETTm2':Dataset_ETT_minute,\n",
    "        'WTH':Dataset_Custom,\n",
    "        'ECL':Dataset_Custom,\n",
    "        'Solar':Dataset_Custom,\n",
    "        'custom':Dataset_Custom,\n",
    "    }\n",
    "    Data = data_dict[self.args.data]\n",
    "    timeenc = 0 if args.embed!='timeF' else 1\n",
    "\n",
    "    if flag == 'test':\n",
    "        shuffle_flag = False; drop_last = True; batch_size = args.batch_size; freq=args.freq\n",
    "    elif flag=='pred':\n",
    "        shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n",
    "        Data = Dataset_Pred\n",
    "    else:\n",
    "        shuffle_flag = True; drop_last = True; batch_size = args.batch_size; freq=args.freq\n",
    "    data_set = Data(\n",
    "        root_path=args.root_path,\n",
    "        data_path=args.data_path,\n",
    "        flag=flag,\n",
    "        size=[args.seq_len, args.label_len, args.pred_len],\n",
    "        features=args.features,\n",
    "        target=args.target,\n",
    "        inverse=args.inverse,\n",
    "        timeenc=timeenc,\n",
    "        freq=freq,\n",
    "        cols=args.cols\n",
    "    )\n",
    "    print(flag, len(data_set))\n",
    "    data_loader = DataLoader(\n",
    "        data_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle_flag,\n",
    "        num_workers=args.num_workers,\n",
    "        drop_last=drop_last)\n",
    "\n",
    "    return data_set, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "aacb61c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = AttrDict({ \"model\": 'lstm-moco',\n",
    "                 \"data\": 'ETTh1', \"data_path\": 'ETTh1.csv', \"pred_len\": 24, \"label_len\": 24,\n",
    "                 \"root_path\": './data/ETT', \"cos_lr\": True, \"loss_lambda\": 0.5,\n",
    "        \n",
    "        \"batch_size\": 32,  \"checkpoints\": './checkpoints/', \"d_model\": 320, \n",
    "        \"e_layers\": 5,  \"features\": 'M', \"freq\": 'h', \"embed\": 'timeF',\n",
    "        \"loss\": 'mse', \"dropout\": 0.1, \"kernel_size\": 3, \"l2norm\": True,\n",
    "#         \"c_out\": 321, \"enc_in\": 321,\n",
    "                 \n",
    "        \n",
    "        \"seq_len\": 48, \"target\": 'OT', \"train_epochs\": 1,  \"mask_rate\": 0.3, \n",
    "                 \n",
    "        \"learning_rate\": 0.001, \"patience\": 3,\n",
    "        \"gpu\": 0, \n",
    "          \n",
    "        \"moco_average_pool\": False, \"data_aug\": \"cost\", \"mare\": False, \"time_feature_embed\": False, \"inverse\": False,\n",
    "        \"cols\": None, \"num_workers\": 0,  \"closs_decay\": False, \n",
    "        \"use_gpu\": False, \"use_multi_gpu\": False, \"des\": \"Exp\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "83480df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "AttrDict({'model': 'lstm-moco', 'data': 'ETTh1', 'data_path': 'ETTh1.csv', 'pred_len': 24, 'label_len': 24, 'root_path': './data/ETT', 'cos_lr': True, 'loss_lambda': 0.5, 'batch_size': 32, 'checkpoints': './checkpoints/', 'd_model': 320, 'e_layers': 5, 'features': 'M', 'freq': 'h', 'embed': 'timeF', 'loss': 'mse', 'dropout': 0.1, 'kernel_size': 3, 'l2norm': True, 'seq_len': 48, 'target': 'OT', 'train_epochs': 1, 'mask_rate': 0.3, 'learning_rate': 0.001, 'patience': 3, 'gpu': 0, 'moco_average_pool': False, 'data_aug': 'cost', 'mare': False, 'time_feature_embed': False, 'inverse': False, 'cols': None, 'num_workers': 0, 'closs_decay': False, 'use_gpu': False, 'use_multi_gpu': False, 'des': 'Exp', 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'detail_freq': 'h'})\n",
      "Use CPU\n",
      "Use Data augmentation method: cost\n",
      "l2norm True\n",
      "Mask Rate: 0.5\n",
      "[INFO] NOT Using Time Features.\n",
      "[INFO] Number of parameters:  971399\n",
      "TCN_MoCo(\n",
      "  (encoder_q): TCNBase(\n",
      "    (enc_embedding): Linear(in_features=7, out_features=64, bias=True)\n",
      "    (encoder): LSTM_Encoder(\n",
      "      (encoder_in): LSTM(64, 64, num_layers=5, batch_first=True, dropout=0.1)\n",
      "      (encoder_out): LSTM(64, 320, batch_first=True, dropout=0.1)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder_k): TCNBase(\n",
      "    (enc_embedding): Linear(in_features=7, out_features=64, bias=True)\n",
      "    (encoder): LSTM_Encoder(\n",
      "      (encoder_in): LSTM(64, 64, num_layers=5, batch_first=True, dropout=0.1)\n",
      "      (encoder_out): LSTM(64, 320, batch_first=True, dropout=0.1)\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (head_q): Sequential(\n",
      "    (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=320, out_features=320, bias=True)\n",
      "  )\n",
      "  (head_k): Sequential(\n",
      "    (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=320, out_features=320, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=320, out_features=7, bias=True)\n",
      "  )\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data_parser = {\n",
    "    'ETTh1':{'data':'ETTh1.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "    'ETTh2':{'data':'ETTh2.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "    'ETTm1':{'data':'ETTm1.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "    'ETTm2':{'data':'ETTm2.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "    'WTH':{'data':'WTH.csv','T':'WetBulbCelsius','M':[12,12,12],'S':[1,1,1],'MS':[12,12,1]},\n",
    "    'ECL':{'data':'ECL.csv','T':'MT_320','M':[321,321,321],'S':[1,1,1],'MS':[321,321,1]},\n",
    "    'Solar':{'data':'solar_AL.csv','T':'POWER_136','M':[137,137,137],'S':[1,1,1],'MS':[137,137,1]},\n",
    "}\n",
    "if args.data in data_parser.keys():\n",
    "    data_info = data_parser[args.data]\n",
    "    args.data_path = data_info['data']\n",
    "    args.target = data_info['T']\n",
    "    args.enc_in, args.dec_in, args.c_out = data_info[args.features]\n",
    "\n",
    "# args.s_layers = [int(s_l) for s_l in args.s_layers.replace(' ','').split(',')]\n",
    "args.detail_freq = args.freq\n",
    "args.freq = args.freq[-1:]\n",
    "args.time_feature_embed = False\n",
    "args.mare = False\n",
    "print('Args in experiment:')\n",
    "print(args)\n",
    "\n",
    "Exp = Exp_Informer\n",
    "exp = Exp(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ab329c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.model=='lstm' or args.model=='tcn' or args.model=='dtcn' or args.model == 'informer-encoder':\n",
    "    model_path = './checkpoints/contrast-{}_{}_contrastL{}_mask{}_l2norm{}_ft{}_sl{}_pl{}_dm{}_el{}_{}_{}/checkpoint.pth'.format(\n",
    "                args.model, args.data, args.loss_lambda, \n",
    "                args.mask_rate, str(args.l2norm), args.features, \n",
    "                args.seq_len, args.pred_len,\n",
    "                args.d_model, args.e_layers, args.des, 0)\n",
    "elif \"moco\" in args.model or args.model==\"cost-e2e\":\n",
    "    model_path = './checkpoints/contrast-{}_{}_contrastL{}_mask{}_l2norm{}_ft{}_timeF{}_mare{}_cldecay{}_sl{}_pl{}_dm{}_el{}_avg{}_cos{}_aug{}_{}_{}/checkpoint.pth'.format(\n",
    "                    args.model, args.data, args.loss_lambda, args.mask_rate, str(args.l2norm), args.features, \n",
    "                    str(args.time_feature_embed), str(args.mare), str(args.closs_decay), args.seq_len, args.pred_len,\n",
    "                    args.d_model, args.e_layers, str(args.moco_average_pool), str(args.cos_lr), \n",
    "                    args.data_aug, args.des, 0)\n",
    "\n",
    "checkpoint = torch.load(\n",
    "    model_path,\n",
    "    map_location=torch.device('cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4d043a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {k.replace(\"tcn\", \"encoder\"): v for k, v in checkpoint.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9fb94fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.model.load_state_dict(checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f0fd3bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "exp.model = exp.model.to(device)\n",
    "exp.model.eval()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f3c960d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val 2857\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vali_data, vali_loader = exp._get_data(flag = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "17e0a34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vali_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5760a40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x152394158fa0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vali_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3b0b9a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion =  nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ed8ff4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqence_line(sp, dim):\n",
    "    input_x = sp[\"input\"].detach().numpy()\n",
    "    target_label = sp[\"label\"][:sp[\"step\"]+1, :].numpy()\n",
    "    \n",
    "    predict = float(sp[\"pred\"][sp[\"step\"], dim])\n",
    "    \n",
    "    concat_ts = np.concatenate((input_x, target_label), axis=0)\n",
    "    concat_ts = list(concat_ts[:, dim])\n",
    "\n",
    "    x = [ind for ind, y in enumerate(concat_ts)]\n",
    "    y = [y for ind, y in enumerate(concat_ts)]\n",
    "    \n",
    "    x.append(len(concat_ts)-1)\n",
    "    y.append(predict)\n",
    "    # y2point = input_x[:, ]\n",
    "\n",
    "    input_end = args.seq_len - args.pred_len + sp[\"step\"] + 1\n",
    "    input_unseen_end = args.seq_len + sp[\"step\"] + 1\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    dim_grad = torch.nn.functional.softmax(sp['gradient'][:, dim].unsqueeze(0), dim=1).numpy()\n",
    "    dim_grad = np.repeat(dim_grad, 2, axis=0)\n",
    "    plt.imshow(dim_grad, cmap='GnBu', alpha=1,  origin=\"upper\", interpolation='nearest', aspect='auto', extent=(-0.5, input_end-0.5, min(y)-0.1, max(y)+0.1))\n",
    "#     np.pad(dim_grad,((0, 0), (0, 23)), 'constant')\n",
    "    plt.plot(x[:input_end], y[:input_end], \"ko-\", label= \"Input\")\n",
    "\n",
    "    plt.plot(x[input_end-1: input_unseen_end], y[input_end-1:input_unseen_end], color=\"grey\", linestyle=\":\",  marker = \"o\", linewidth=1, markersize=3, label= \"Unseen\")\n",
    "    \n",
    "    plt.plot(x[input_end-1], y[input_end-1], \"ko-\")\n",
    "    \n",
    "    plt.plot(x[input_unseen_end-1:-1], y[input_unseen_end-1:-1], \"ro\", markersize=10, label= \"Label\")\n",
    "    plt.plot(x[-1], y[-1], color=\"orange\", marker = \"s\", linestyle = 'None', markersize=8, label= \"Prediction\")\n",
    "    \n",
    "    plt.xticks([x for x in range(0, len(x), 2)])\n",
    "    plt.ylim(ymax = max(y)+0.1, ymin = min(y)-0.1)\n",
    "    \n",
    "    plt.grid(color='grey', linestyle='--', linewidth=0.5)\n",
    "#     plt.yticks([round(max(y) + 0.5 * y, 2) for y in range(int((max(y)-min(y))/0.5)+1)])\n",
    "\n",
    "    plt.legend(loc='best') #lower right\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4594fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd40899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55435e61",
   "metadata": {},
   "source": [
    "### Average over batch and dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "511739f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([32, 48, 7])\n",
      "1 torch.Size([32, 48, 7])\n",
      "2 torch.Size([32, 48, 7])\n",
      "3 torch.Size([32, 48, 7])\n",
      "4 torch.Size([32, 48, 7])\n",
      "5 torch.Size([32, 48, 7])\n",
      "6 torch.Size([32, 48, 7])\n",
      "7 torch.Size([32, 48, 7])\n",
      "8 torch.Size([32, 48, 7])\n",
      "9 torch.Size([32, 48, 7])\n",
      "10 torch.Size([32, 48, 7])\n"
     ]
    }
   ],
   "source": [
    "batch_grad = []\n",
    "for ind, batch in enumerate(vali_loader):\n",
    "    print(ind, batch[0].shape)\n",
    "    exp.model.eval()\n",
    "    seq_x, seq_y, seq_x_mark, seq_y_mark = map(lambda x: x.float().to(device), batch)\n",
    "#     seq_x = seq_x.float()\n",
    "#     seq_y = seq_y.float()\n",
    "#     seq_x_mark = seq_x_mark.float()\n",
    "    exp.model.train()\n",
    "    seq_x.requires_grad = True\n",
    "    \n",
    "    if 'moco' in args.model or \"cost\" in args.model:\n",
    "        prediction_y, _, contrast_loss  = exp.model(seq_x, seq_x_mark)\n",
    "    else:\n",
    "        prediction_y, _ , _ = exp.model(seq_x)\n",
    "\n",
    "    seq_y = seq_y[:,-args.pred_len:, :]\n",
    "\n",
    "    buff = []\n",
    "    for i in range(args.pred_len):\n",
    "        pred = prediction_y[:, i, :]\n",
    "        label = seq_y[:, i, :]\n",
    "\n",
    "        loss = criterion(pred, label)\n",
    "    #     print(loss)\n",
    "\n",
    "        exp.model.zero_grad()\n",
    "        \n",
    "        if i == args.pred_len-1:\n",
    "            loss.backward(retain_graph=False)\n",
    "        else:\n",
    "            loss.backward(retain_graph=True)\n",
    "            \n",
    "        data_grad = seq_x.grad.detach()\n",
    "\n",
    "        end = args.seq_len #- args.pred_len + i + 1\n",
    "        begin = 0 #end-args.pred_len\n",
    "        buff.append(torch.abs(data_grad[:,begin: end]))\n",
    "    #     print(data_grad.shape)\n",
    "    buff = [torch.sum(torch.sum(x, 0), -1).unsqueeze(0) for x in buff]\n",
    "    \n",
    "    batch_grad.append(buff)\n",
    "    \n",
    "    if ind == 10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd201b94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmap = sns.cm.rocket_r\n",
    "for i in range(args.pred_len):\n",
    "    print(i)\n",
    "    temp = []\n",
    "    for x in batch_grad:\n",
    "        temp.append(x[i])\n",
    "        \n",
    "    conbine = torch.cat(temp, dim=0)\n",
    "    avg_all = torch.sum(conbine, 0).unsqueeze(0).numpy()\n",
    "#     avg_all = torch.nn.functional.softmax(torch.sum(conbine, 0).unsqueeze(0), dim=1).numpy()\n",
    "\n",
    "    plt.figure(figsize=(5, 1))\n",
    "    sns.heatmap(avg_all, cmap = cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bada40",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b184563",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.cm.rocket_r\n",
    "for i in range(args.pred_len):\n",
    "    print(i)\n",
    "    temp = []\n",
    "    for x in batch_grad:\n",
    "        temp.append(x[i])\n",
    "        \n",
    "    conbine = torch.cat(temp, dim=0)\n",
    "#     avg_all = torch.sum(conbine, 0).unsqueeze(0).numpy()\n",
    "    avg_all = torch.nn.functional.softmax(torch.sum(conbine, 0).unsqueeze(0), dim=1).numpy()\n",
    "\n",
    "    plt.figure(figsize=(5, 1))\n",
    "    sns.heatmap(avg_all, cmap = cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0515003",
   "metadata": {},
   "source": [
    "## sample wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c042a558",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([32, 48, 7])\n",
      "1 torch.Size([32, 48, 7])\n",
      "2 torch.Size([32, 48, 7])\n",
      "3 torch.Size([32, 48, 7])\n",
      "4 torch.Size([32, 48, 7])\n",
      "5 torch.Size([32, 48, 7])\n",
      "6 torch.Size([32, 48, 7])\n",
      "7 torch.Size([32, 48, 7])\n",
      "8 torch.Size([32, 48, 7])\n",
      "9 torch.Size([32, 48, 7])\n",
      "10 torch.Size([32, 48, 7])\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "for ind, batch in enumerate(vali_loader):\n",
    "    print(ind, batch[0].shape)\n",
    "    exp.model.eval()\n",
    "    seq_x, seq_y, seq_x_mark, seq_y_mark = map(lambda x: x.float().to(device), batch)\n",
    "    \n",
    "    exp.model.train()\n",
    "    seq_x.requires_grad = True\n",
    "    \n",
    "    if 'moco' in args.model or \"cost\" in args.model:\n",
    "        prediction_y, _, contrast_loss  = exp.model(seq_x, seq_x_mark)\n",
    "    else:\n",
    "        prediction_y, _ , _ = exp.model(seq_x)\n",
    "\n",
    "    seq_y = seq_y[:,-args.pred_len:, :]\n",
    "\n",
    "    buff = []\n",
    "    for sample in range(seq_y.shape[0]):\n",
    "        for i in range(0, 10):\n",
    "            tmp = {}\n",
    "            pred = prediction_y[sample, i, :]\n",
    "            label = seq_y[sample, i, :]\n",
    "            \n",
    "            tmp[\"step\"] = i+1\n",
    "            tmp[\"input\"] = seq_x[sample, :, :].cpu().detach()\n",
    "            tmp[\"pred\"] = prediction_y[sample, :, :].cpu().detach()\n",
    "            tmp[\"label\"] = seq_y[sample, :, :].cpu().detach()\n",
    "            \n",
    "            \n",
    "            loss = criterion(pred, label)\n",
    "#             print(loss)\n",
    "            \n",
    "            tmp[\"loss\"] = float(loss.cpu().detach())\n",
    "            \n",
    "            exp.model.zero_grad()\n",
    "\n",
    "            if i == args.pred_len-1 and sample == seq_y.shape[0]-1:\n",
    "                loss.backward(retain_graph=False)\n",
    "            else:\n",
    "                loss.backward(retain_graph=True)\n",
    "\n",
    "            data_grad = seq_x.grad.detach()\n",
    "\n",
    "            end = args.seq_len - args.pred_len + i + 1\n",
    "            begin = 0 #end-args.pred_len\n",
    "\n",
    "            tmp[\"gradient\"] = torch.abs(data_grad[sample, begin: end, :]).cpu().detach()\n",
    "            \n",
    "            samples.append(tmp)\n",
    "\n",
    "    if ind == 10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0d87e413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3520"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2d0c2a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([x[\"step\"] for x  in samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c5d676db",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"min\"\n",
    "tg_index = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d98275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, sp in enumerate(samples):\n",
    "    if mode == \"min\":\n",
    "        if sp['loss'] == min([x['loss'] for x in samples]):\n",
    "            print(ind, sp['loss'])\n",
    "            break\n",
    "    elif mode == \"max\":\n",
    "        if sp['loss'] == max([x['loss'] for x in samples]):\n",
    "            print(ind, sp['loss'])\n",
    "            break\n",
    "    elif mode == \"index\":\n",
    "        if ind == tg_index:\n",
    "            print(ind, sp['loss'])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85105ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cmap = sns.cm.rocket_r\n",
    "\n",
    "for dim in range(sp['gradient'].shape[-1]):\n",
    "    sqence_line(sp, dim)\n",
    "#     dim_grad = sp['gradient'][:, dim].unsqueeze(0).numpy()\n",
    "    dim_grad = torch.nn.functional.softmax(sp['gradient'][:, dim].unsqueeze(0), dim=1).numpy()\n",
    "\n",
    "#     plt.figure(figsize=(10, 1))\n",
    "#     sns.heatmap(dim_grad, cmap = cmap, linewidths=0.8, cbar=False)\n",
    "#     break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fa33a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491df235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60af6cc5",
   "metadata": {},
   "source": [
    "## print all dimensions in the input in a single picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e625f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"./output_receptive_field\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e3d0b760",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def group_plot(sp, ind, output_dir):\n",
    "    feature_size = min(sp['gradient'].shape[-1], 20)\n",
    "\n",
    "    fig, axs = plt.subplots(feature_size, figsize=(15, 3*feature_size))\n",
    "\n",
    "    for dim in range(feature_size):\n",
    "        input_x = sp[\"input\"].detach().numpy()\n",
    "        target_label = sp[\"label\"][:sp[\"step\"]+1, :].numpy()\n",
    "\n",
    "        predict = float(sp[\"pred\"][sp[\"step\"], dim])\n",
    "\n",
    "        concat_ts = np.concatenate((input_x, target_label), axis=0)\n",
    "        concat_ts = list(concat_ts[:, dim])\n",
    "\n",
    "        x = [ind for ind, y in enumerate(concat_ts)]\n",
    "        y = [y for ind, y in enumerate(concat_ts)]\n",
    "\n",
    "        x.append(len(concat_ts)-1)\n",
    "        y.append(predict)\n",
    "        # y2point = input_x[:, ]\n",
    "\n",
    "        input_end = args.seq_len - args.pred_len + sp[\"step\"] + 1\n",
    "        input_unseen_end = args.seq_len + sp[\"step\"] + 1\n",
    "\n",
    "        dim_grad = torch.nn.functional.softmax(sp['gradient'][:, dim].unsqueeze(0), dim=1).numpy()\n",
    "        dim_grad = np.repeat(dim_grad, 2, axis=0)\n",
    "        axs[dim].imshow(dim_grad, cmap='GnBu', alpha=1,  origin=\"upper\", interpolation='nearest', aspect='auto', extent=(-0.5, input_end-0.5, min(y)-0.1, max(y)+0.1))\n",
    "        #     np.pad(dim_grad,((0, 0), (0, 23)), 'constant')\n",
    "        axs[dim].plot(x[:input_end], y[:input_end], \"ko-\", label= \"Input\")\n",
    "\n",
    "        axs[dim].plot(x[input_end-1: input_unseen_end], y[input_end-1:input_unseen_end], color=\"grey\", linestyle=\":\",  marker = \"o\", linewidth=1, markersize=3, label= \"Unseen\")\n",
    "\n",
    "        axs[dim].plot(x[input_end-1], y[input_end-1], \"ko-\")\n",
    "\n",
    "        axs[dim].plot(x[input_unseen_end-1:-1], y[input_unseen_end-1:-1], \"ro\", markersize=10, label= \"Label\")\n",
    "        axs[dim].plot(x[-1], y[-1], color=\"orange\", marker = \"s\", linestyle = 'None', markersize=8, label= \"Prediction\")\n",
    "\n",
    "        axs[dim].set_xticks([x for x in range(0, len(x), 2)])\n",
    "        axs[dim].set_ylim(ymax = max(y)+0.1, ymin = min(y)-0.1)\n",
    "\n",
    "        axs[dim].grid(color='grey', linestyle='--', linewidth=0.5)\n",
    "        #     plt.yticks([round(max(y) + 0.5 * y, 2) for y in range(int((max(y)-min(y))/0.5)+1)])\n",
    "\n",
    "        axs[dim].legend(loc='best') #lower right\n",
    "\n",
    "\n",
    "    fig.suptitle(f\"Receptive Field of {args.model}. \\n Dataset: {args.data}, Sample MSE = {str(sp['loss'])[:6]} at {sp['step']}th forecasting step. \\nInput length = {args.seq_len}, Prediction length = {args.pred_len}. \\n\\n\", fontsize=16, wrap=True)\n",
    "\n",
    "    fig.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "\n",
    "    file_name = f\"{output_dir}/model-{args.model}_data-{args.data}_feature-{feature_size}_val-sample{ind}_pred-at-{sp['step']}_inputleng-{args.seq_len}_predleng-{args.pred_len}.png\"\n",
    "    fig.savefig(file_name, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "42e7d8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3520"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)\n",
    "\n",
    "# candidate_ind = [x for x in range(len(samples)) if random.uniform(0, 1) > 0.97][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "daa17b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 43, 92, 108, 139, 166, 208, 229, 288, 302, 319, 377, 465, 474, 522, 599, 600, 634, 757, 837, 862, 887, 892, 964, 997, 1017, 1041, 1052, 1063, 1107, 1288, 1318, 1326, 1388, 1427, 1433, 1472, 1515, 1603, 1610, 1624, 1629, 1819, 1893, 1897, 1911, 1915, 1930, 2096, 2159, 2291, 2321, 2332, 2340, 2345, 2347, 2373, 2521, 2573, 2607, 2645, 2666, 2676, 2860, 2862, 2898, 2953, 2976, 3020, 3051, 3105, 3126, 3135, 3190, 3268, 3287, 3306, 3327, 3363, 3407, 3420, 3427, 3494]\n"
     ]
    }
   ],
   "source": [
    "print(candidate_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "09f9b729",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = out_dir + \"/\" + args.model\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "31b6aaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for ind, sp in enumerate(samples):\n",
    "    if ind in candidate_ind:\n",
    "        group_plot(sp, ind, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5df3b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls output_receptive_field/ | wc -l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "47048d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r output_receptive_field/tcn/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6715f9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
